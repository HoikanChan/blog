## 字段、索引、表引擎

### 数据类型

####   数  值

- tinyint：小整数，1个字节，无符号（0,255）；有符号（-128,127）
- int：大整数，4个字节，无符号（0，4294967295）；有符号（-2147483648，2147483647）
- bigint：极大整数，8个字节
- float：单精度浮点数，4字节、表引擎
- double：双精度浮点数，8字节
- decimal：小数值；长度依赖于decimal(M,D),M>D,长度M+2，反之D+2

#### 字 符 串

- char：定长字符串，（0-255字节）
- varchar：变长字符串，（0-65535字节）

#### 日期时间

- date：日期，3个字节，YYYY-MM-DD
- datetime：日期时间，8个字节，YYYY-MM-DD HH:MM:SS
- timestamp:4个字节，YYYYMMDD HHMMSS，注意（一个表只能有一个字段为current_timestamp，结束时间2038 01-19）

####  索   引

##### 索引种类

- primary：主键，不可为NULL，不可重复
- unique：唯一索引，不可重复，可以为NULL，NULL可以出现多次
- normal：普通索引，可以出现多次
- fulltext：全文索引，用于分词搜索；5.6之前只能用MyISAM，5.6以后可以用在InnoDB
- 组合索引：多个列组成索引，用于组合搜索，“最左前缀原则”

##### 索引类型

- FULL TEXT：全文索引，用于char、varchar、text这种列上，为了解决WHERE name LIKE “%word%"这类针对文本的模糊查询效率较低的问题。
- HASH：由于HASH近乎百分之百的唯一性和键值对的存储形式，用在“=”、in、<=>条件下效率及高，但是对于范围查询、排序及组合索引效率不高；
- BTREE：mysql默认和最常用的索引类型，按照算法将索引存入树形结构（二叉树），每次查询都是从根节点root开始，依次遍历node；

#####   缺   点

1、insert、update、delete需要维护索引文件增加开销；

2、使用索引会建立索引文件占据存储空间

##### 索引命中

1、使用LIKE子句时，%或者_开头会造成索引无法命中；

- 索引未命中
- 索引未命中
- 索引命中

2、数据类型不匹配时，会造成索引无法命中；

- 索引命中
- 索引命中
- 使用索引，但是全表扫描
- 索引命中

3、复合索引，不符合最左前缀时会造成索引无法命中；（a,b,c三列组成复合索引，a|(a,b)|(a,b,c)都会命中索引）

- explain的type类型
- system：表中只有一条记录等于系统表，可以忽略不计
- const：表示通过索引一次就找到了，一般会在primary key和unique索引上；
- eq_ref：唯一性索引扫描，常见于primary key和unique索引
- ref：非唯一性索引，返回索引匹配的所有行，
- range：检索范围行，常见于where条件出现了< 、> 、in 、between等查询，开始于索引的某一点，结束于另一点；
- index：历索引树，通俗的解释：只查询带索引的字段，读全表，从索引中读取，比all速度快；
- all：全表扫描找到匹配的行，读磁盘

#### 表 引 擎

##### 常用类型

- InnoDB：使用聚集索引，会按照主键进行聚簇，没有主键使用非空的唯一索引，如果没有非空唯一索引，InnoDB会定义隐藏的主键进行聚簇，主键必然是聚簇索引，但是聚簇索引不一定是主键；索引和数据在一起，找到索引就找到数据；
- MyISAM：堆组织表，数据存储位置随机，没有特定的顺序，存储速度较快，查询数据时需要读取全部记录筛选；数据和索引分开存放，查找的时候先查索引，根据索引查数据

#### 事务

##### 什么是事务

事务是数据库执行过程中的一个逻辑单位，包含了一组对数据库的读/写操作

#### 事务的目的

- 为数据库操作序列提供了一个回滚的方法，提供了数据库即使在异常状态下仍能保持数据一致性的方法
- 当多个应用程序并发访问数据库时，可以在这些应用程序之间提供一个隔离的方法，避免彼此相互影响

##### 事务的特性

- 原子性（atomic）——  事务必需是原子工作单元，对于数据修改，要么全都执行，要么全都不执行
- 一致性（consistent）——  事务在完成时，所有数据都保持一致
- 隔离性（isolation）—— 由并发事务所作的修改必须与任何其它并发事务所作的修改隔离。事务查看数据时数据所处的状 态，要么是另一并发事务修改它之前的状态，要么是另一事务修改它之后的状态，事务不会查看中间状态的数据

查看当前会话隔离级别：

```sql
SELECT @@tx_isolation;
```

查看系统隔离级别：

```sql
SELECT @@global.tx_isolation;
```

设置隔离级别：

1. 当前会话，

```sql
SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
```

2. 系统，

```sql
SET GLOBAL TRANSACTION ISOLATION LEVEL REPEATABLE READ;
```

- 持久性（duration）—— 事务完成后，对数据的修改是永久的





##### 事务的并发

- 脏读 —— 事务A读取了事务B更新的数据，事务B回滚，那么事务A读取的数据是脏数据
- 不可重复读 —— 事务A多次读取同一数据，事务B在事务A读取的过程中，对数据做了更新并提交，导致事务A多次读取到的数据不一致
- 幻读 —— 系统管理员A批量将员工的评分改为ABCDE等级，系统管理员B写入一条具体分数的员工考核记录，当A改完时候发现有一条记录没变更过来，好像出现幻觉一样，这就是幻读
- 小结 —— 不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表

##### 事务的隔离级别

- 读未提交（read-uncommitted）：脏读、不可重复读、幻读、
- 不可重复读（read-committed）：脏读、不可重复读、幻读
- 可重复读（repeatable-read）：脏读、不可重复读、幻读

- 串行化（serializable）：脏读、不可重复读、幻读

##### 小结

1、事务隔离级别为读提交时，写数据会锁住相应的行

2、事务隔离级别为可重复读时，如果检索条件有索引（包括主键索引）的时候，默认加锁方式是next-key 锁；如果检索条件没有索引，更新数据时会锁住整张表。一个间隙被事务加了锁，其他事务是不能在这个间隙插入记录的，这样可以防止幻读

3、事务隔离级别为串行化时，读写数据都会锁住整张表

4、隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。

#### 锁

#####          使用方式

- 乐观锁：

  总是假设最好的情形，每次拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间有没有人更新过数据，可以使用版本号机制和CAS算法；

- 悲观锁：

  总是假设最坏的情形，每次拿数据的时候都认为别人会修改，所以每次拿数据都会上锁，别人拿数据时候就会阻塞直到拿到锁为止；

  ##### 锁 粒 度

- 行级锁：

- 粒度最小的，发生锁定资源争抢的比较小，可以提供更高的并发量，但是获取锁和释放锁发生次数比较多，需要做较多的事情，容易出现死锁

- 页级锁：

- 页级锁介于行级锁和表级锁之间，获取锁和释放锁速度也介于两者之间，锁冲突概率和支持并发量也介于两者之间，会跟行级锁一样出现死锁；使用页级锁定的主要是BerkeleyDB存储引擎

- 表级锁：

- 粒度最大的锁，特点：实现逻辑简单，带来的负面影响最小，获取锁和释放锁速度特别快，一次可以锁定整个表，避免了死锁的出现；缺点：锁粒度大，锁冲突概率高，并发支持量最低；MyISAM引擎使用表级锁；

###### 锁 级 别

- 共享锁（读锁）（S）（Shared Lock）事务T对数据D加共享锁，其他事务只能对数据D加共享锁，不能加排它锁
- 排它锁（写锁）（X）（Exclusive Lock）事务T对数据D加排它锁，其他事务对数据D不能加共享锁，也不能加排它锁
- 意向锁  意向共享锁、意向排它锁
- 间隙锁

#####   操  作  

- DDL锁
- DML锁

##### 加锁方式

- 自动锁
- 显示锁

#####   其  他  

- 死锁
- MVCC





## 读写分离

### 原 理

读写分离的基本原理是将数据库读写操作分散到不同的节点上 读写分离

### 实现方式

- 数据服务器搭建主从集群，一主一从、一主多从、双主热备都可以
- 数据库主机负责写操作，从机负责读操作
- 数据库主机通过复制将数据同步到从机，每台数据服务器存储了所有的业务数据
- 业务逻辑控制将写操作分发给数据主机，读操作分发给数据从机

### 复制延迟

##### 延迟例子

MySql的主从复制延迟可能达到1s以上，如果大量数据同步的话1分钟也有可能，复制延迟带来的的问题就是：如果业务服务器将数据写入数据主机后立刻进行读取(1s内)，读操作访问的是数据从机，这时候数据主机还未将数据复制过来，会读取不到最新数据，业务有可能出现问题。例如用户注册完立即登录，业务服务器会提示“尚未注册”，而用户刚刚已经注册成功；

##### 解决方法

###### 写操作之后的读操作指向数据主机：

业务的强制绑定，对业务的侵入和影响较大

###### 读从机失败之后再读一次主机：

“二次读取”，这种方式和业务无绑定，只需要更改数据库访问的业务逻辑，实现代价较低；

如果存在多次二次读取，会大大增加主机的读操作压力，比如暴力破解，可以加锁，但是会影响用户体验

###### 关键业务读写指向主机，非关键业务读写分离

用户的注册和登录业务读写操作全部访问主机，用户的其他相关信息可以使用读写分离，假如用户更新了介绍在查看时看到的还是未更新的，影响和不能登录相比要小了很多，在接受范围；

### 分配机

#### 程序代码封装（中间层）

- 在代码中抽象一个数据访问层，实现读写分离和数据库连接管理
- 业务服务器通过数据库访问层访问数据库
- Yii实现读写分离，通过调用 yii\db\Command::execute() 来执行的语句都被视为写操作， 而其他所有通过调用 yii\db\Command 中任一 "query" 方法来执行的语句都被视为读操作。还可以通过 Yii::$app->db->slave 来获取当前有效的从库连接。在从库上执行：Yii::$app->db->createCommand('SELECT * FROM user LIMIT 10')->queryAll();    在主库上执行：Yii::$app->db->createCommand("UPDATE user SET username='demo' WHERE id=1")->execute();

#### 中间件封装

1. mysqlRouter

Router作为一个流量转发层，位于应用与MySQL服务器之间，其功能类似于LVS。应用不再直连MySQL Servers，而是与Router相连。根据Router的配置，将会把应用程序的读写请求转发给下游的MySQL Servers。mysqlRouter集群发生变更时无需修改应用中的设置，只需修改Router的配置即可；不支持分库分表

2. mycat

支持MySQL原生协议，跨语言、跨平台、跨数据库的中间件；支持读写分离，支持MySQL主从；支持分布式事务；支持sum、count、max等聚合函数；支持单库任意join，支持跨库2表join；支持分库分表；

## 分库分表

#### 单数据服务器瓶颈

- 数据量太大，读写性能就会下降，有索引，索引文件也会变大，性能同样会下降
- 数据文件变大，随之带来的问题就是数据的备份和恢复耗费时间变长
- 数据文件越大，数据丢失的风险也越高

#### 业务分库

业务分库就是根据不同的业务将用户数据分散到不同的数据库服务器

带来的问题

- join问题: 表分布在不同的数据库中，不能使用join查询
- 事务问题: 分布在不同的数据库中，修改数据不能再一个事务中修改
- 成本增加

#### 分表

将不同业务分散到不同的数据库中，但是根据业务的发展，某些业务也会达到服务器的瓶颈

##### 水平和垂直分表

- 从上往下切就是垂直分表，切出来的表记录数相同，会有不同的列，根据右侧示例图中的垂直拆分，会有两个表一个包含ID，name，age，sex；一个表包含ID，nickname，description；
- 从左往右切就是水平分表，切出来的表记录数不同，每个表都是相同的列，根据右侧示例图的水平拆分，两个表都包含ID、name、age、sex、nickname、description；一个表记录ID：1-999999；一个表记录ID：1000000-9999999

##### 垂直分表

垂直分表适合将某些不常用但是占据空间比较大的拆分出去，右侧示例图中的，用户信息nickname、description占空间较多，使用频率相对低一些，可以拆分出去

垂直拆分带来的问题就是表操作次数增加，原本一次查询可以获取用户的name、age、sex、nickname、description信息，现在需要查询两张表的数据合并起来

##### 水平分表

1. 场景

水平分表适合行数比较多的表，根据业务复杂度不同，业务复杂的单表记录过千万就有可能带来风险，业务简单的表过亿也影响不大，单表记录过千万需要引起注意，实际拆分根据业务场景

复杂度

2. 路由

水平拆分之后，要根据路由算法计算出数据属于哪个子表，会带来一定得复杂度

##### 路由算法

1. 范围路由

- 选取有序的字段比如整形、时间戳，作为路由的条件，最常见的就是根据用户ID作为拆分条件，比如驼驮+，根据企业ID，将企业的点检执行记录和记录详情分表，路由算法对10000取模，（企业ID：1-9999放在一表，企业ID：10000-19999放在二表，依次类推）
- 范围路由的设计复杂点主要在于分段范围的大小，分段太小增加维护成本，分段太大，单表数据仍然会遇到瓶颈
- 范围路由的优点，可以随着业务的扩展增加新的表，平滑扩展，不影响现有的数据
- 范围路由缺点，有可能数据分布不均匀，负载不够均衡，例如总共1000万数据，可能某个分区只有几千条，某个分区有900万条

2. hash路由

- 选取某个列或者几个列的值进行hash运算，数据根据hash运算结果分配到不同的表中
- hash路由的设计复杂点在于初始表数量的选取上，表数量太多维护麻烦，表数量太少存在性能瓶颈，扩容的话就需要重新分布所有的数据
- hash路由的优点和范围路由基本相反，数据分布很均匀，但是扩容麻烦，需要重新分布数据

3. 配置路由

- 配置路由就是增加一张路由表来记录路由信息
- 例如在驼驮+中加一个org_route表，每增加一个企业，企业id会对应一个tableId
- 配置路由设计简单，使用灵活，扩容不受影响，如果迁移数据的话修改对应的路由表数据就可以
- 配置路由的缺点就是需要多查询一次，影响性能，潜在的风险就是如果路由表本身数据量巨大，路由表自身将变成性能瓶颈，如果继续分表的话，将会进入一个死循环

##### join操作

水平切割之后如果数据存在多个表中需要将水平切割的表与join表多次查询，然后合并数据

##### count操作

获取记录总数用于分页或者展示

解决方式

1. count相加: 业务代码中根据条件对每个分表进行count（），然后将结果相加操作简单，性能较低
2. 增加统计表

- 新增一张统计表，用来统计相关信息
- 性能较高，一次查询就可以获取统计信息
- 数据一致性比较难保持，如果不在一个事务中处理会出现分表更新成功，统计表未更新成功
- 会增加写压力，分表的insert和delete操作都要对统计表做update，对于实时性要求不高的业务，可以把update操作异步执行来降低写压力

##### orderby操作

水平切割之后数据散列在多个表中，order by操作只能查询所有数据之后汇总在业务层处理